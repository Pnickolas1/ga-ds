{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# K Means Example\n",
    "\n",
    "In this exercise, you will code up your implementation of K Means clustering. Included is a rough algorithm. Make sure you understand it and are able to express it in your head before moving on.\n",
    "\n",
    "```\n",
    "Choose `n_k`: the number of clusters\n",
    "Choose `n_iter`: the number of total iterations to run k means\n",
    "Set cluster_labels: this is an array or series that is the length of your input data rows. \n",
    "  This array corresponds to the predictions or label associated with each data row.\n",
    "\n",
    "Randomly select n_k of your data points to be the initial centroid positions.\n",
    "\n",
    "Now, for each iter in n_iter:\n",
    "\n",
    "  For each point in your data points:\n",
    "     Get the squared distance of the point to all of the centroids. \n",
    "     (i.e. squared l2 norm, or squared euclidean distance)\n",
    "     Assign the cluster_label of this point to the label of the closest centroid\n",
    " \n",
    "  For each centroid in n_k:\n",
    "     Grab all the points associated with this cluster.\n",
    "     Set the centroid's new position as the mean of all of these points along each dimension\n",
    "  \n",
    "  Return cluster_labels\n",
    "\n",
    "```\n",
    "\n",
    "In addition, play with this link until you feel comfortable with the algorithm in your head\n",
    "\n",
    "http://www.naftaliharris.com/blog/visualizing-k-means-clustering/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Dont need to touch\n",
    "\n",
    "# Generate Fake Data\n",
    "centroids = [ [1.0,1.5],[2.5,2.8],[1.0,4.0] ]\n",
    "\n",
    "data = pd.DataFrame(np.zeros((150,2)), columns=['x1','x2'])\n",
    "\n",
    "for cidx,c in enumerate(centroids):\n",
    "    for idx in range(50):\n",
    "        data.ix[50*cidx + idx,0:2] = [c[0],c[1]] + np.random.normal(0,.4,2)\n",
    "\n",
    "X = data[ ['x1','x2'] ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Dont need to touch\n",
    "\n",
    "def draw2DClusters(data, labels=None, title=\"Clustered Points\"):\n",
    "    \"\"\"\n",
    "    draw2DClusters takes in a dataframe or matrix with m rows, and 2 columns (i.e. two features)\n",
    "    as well as a series of integer labels that incidate which cluster they belong to\n",
    "    \n",
    "    This function will plot a scatter with the appropriate scatters labeled. If there are no labels specified\n",
    "    then will plot all with the same color\n",
    "    \"\"\"\n",
    "    if labels is None:\n",
    "        labels = np.zeros(data.shape[0])\n",
    "    \n",
    "    assert(data.shape[1] == 2) # Input dataframe or matrix must have 2 columns to properly plot this\n",
    "    labels = labels.astype(int)\n",
    "    color_map = [ plt.cm.rainbow(i) for i in np.linspace(0, 1.0, len(np.unique(labels)))]\n",
    "\n",
    "    for cidx, c in enumerate(np.unique(labels)):\n",
    "        X_sub = X.ix[ labels == c, :]\n",
    "        plt.scatter(X_sub.iloc[:,0],X_sub.iloc[:,1],s=50,alpha=0.5,c=color_map[cidx])\n",
    "        plt.xlabel(r\"Feature $x_1$\"), plt.ylabel(r\"Feature $x_2$\"), plt.title(title)\n",
    "\n",
    "        centroid = np.mean(X_sub)\n",
    "        plt.plot(centroid[0],centroid[1],'*',markersize=30,alpha=0.75,c=color_map[cidx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Do touch\n",
    "\n",
    "from scipy.spatial import distance\n",
    "\n",
    "def kmeans(X, n_k, n_iter, standardize=True):\n",
    "    '''\n",
    "    X: Dataframe or matrix each column being a feature\n",
    "    n_k: Number of clusters\n",
    "    n_iter: Number of iterations to go through\n",
    "    standardize: Should each feature be standardized prior to clustering\n",
    "    \n",
    "    Returns a series of the class idx labels\n",
    "    '''\n",
    "    X = X.copy()\n",
    "    \n",
    "    # if standardize set true, then standardize by each column\n",
    "    if standardize:\n",
    "        col_std = np.sqrt(np.var(X,axis=0,keepdims=True))\n",
    "        X = X / col_std\n",
    "\n",
    "    # Set up return array\n",
    "    cluster_labels = np.zeros(len(X))\n",
    "\n",
    "    # TODO: Sample n_k points from the X dataframe. Choose these as the clusters\n",
    "    # It may help to save centroids as a dict with key = label, value = centroid point\n",
    "\n",
    "    \n",
    "    \n",
    "    ## End TODO\n",
    "    \n",
    "    for itr in range(n_iter):\n",
    "        for idx in range(len(X)):\n",
    "            \n",
    "            #TODO\n",
    "            # Compute the distance of each point to each centroid. \n",
    "            # Set cluster_labels of idx as the closest centroid\n",
    "            # It may help to use the euclidean function in distance\n",
    "            # Remember to use the SQUARED euclidean distance! \n",
    "            \n",
    "\n",
    "                    \n",
    "            #End TODO\n",
    "\n",
    "        #TODO\n",
    "        # For each cluster, compute the new centroid as the mean of the points\n",
    "        # that are a part of the cluster.\n",
    "\n",
    "        \n",
    "        \n",
    "        # End TODO\n",
    "        \n",
    "\n",
    "    return cluster_labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Run this after you are sure of your implementation\n",
    "\n",
    "# Test 1 -- Output should look similar to the sklearn impl, par for the actual color choices\n",
    "plt.figure(figsize=(10,5))\n",
    "\n",
    "plt.subplot(1,2,1)\n",
    "cluster_labels = kmeans(X,3,10, standardize=True)\n",
    "draw2DClusters(X,cluster_labels,title=\"Your K Means\")\n",
    "\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "from sklearn import cluster\n",
    "kn = cluster.KMeans(n_clusters=3)\n",
    "kn.fit(X)\n",
    "cluster_labels = kn.predict(X)\n",
    "draw2DClusters(X,cluster_labels,title=\"SKLearn KMeans\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Run this after you are sure of your implementation\n",
    "\n",
    "\n",
    "# Test 2 - This tests how your impl looks with 1 vs. 3 vs. 10 clusters\n",
    "#1 Cluster should have centroid at the center\n",
    "# 3 Cluster should have a centroid over each natural cluster\n",
    "# 10 cluster should have 3 or 4 clusters roughly located around each natural cluster\n",
    "\n",
    "plt.figure(figsize=(15,5))\n",
    "plt.subplot(1,3,1)\n",
    "cluster_labels = kmeans(X,1,10, standardize=True)\n",
    "draw2DClusters(X,cluster_labels,title=\"1 Cluster\")\n",
    "\n",
    "# Generate 3 clusters and draw\n",
    "plt.subplot(1,3,2)\n",
    "cluster_labels = kmeans(X,3,10, standardize=True)\n",
    "draw2DClusters(X,cluster_labels,title=\"3 Clusters\")\n",
    "\n",
    "\n",
    "# Generate 10 Clusters and draw\n",
    "plt.subplot(1,3,3)\n",
    "cluster_labels = kmeans(X,10,10, standardize=True)\n",
    "draw2DClusters(X,cluster_labels,title=\"10 Clusters\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SKLearn K Means Implementation\n",
    "\n",
    "Let's look into some of the additional features and benefits that sklearn's implementation gives us.\n",
    "\n",
    "* Inertia\n",
    "* Multiple runs of kmeans\n",
    "* KMeans++\n",
    "* Stopping conditions\n",
    "* Transformations of data into cluster space [ BE CAREFUL HERE, gives euclidean, not Squared euclidean distance ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "\n",
    "km = KMeans(n_clusters=3,n_init=1,random_state=0)\n",
    "\n",
    "km.fit(X)\n",
    "\n",
    "km_clusters = km.predict(X)\n",
    "\n",
    "draw2DClusters(X,km_clusters,\"SKLearn Clusters\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print km.inertia_\n",
    "print np.sum(np.power([km.transform(X)[idx,x] for idx,x in enumerate(km_clusters)],2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plotting out Inertia, Avg Dist, Cohesion, Separation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "inertia = []\n",
    "avgDist = []\n",
    "cohesion = []\n",
    "separation = []\n",
    "\n",
    "for n_k in range(1,20):\n",
    "    km = KMeans(n_clusters=n_k)\n",
    "    km.fit(X)\n",
    "    \n",
    "    inertia.append(km.inertia_)\n",
    "    \n",
    "    distToCenters = np.power([km.transform(X)[idx,x] for idx,x in enumerate(km.labels_)],2)\n",
    "    avgDist.append( np.mean(distToCenters) )\n",
    "\n",
    "    clust_coh = []\n",
    "    for c in np.unique(km.labels_):\n",
    "        clust_coh.append( np.sum(np.power([km.transform(X)[idx,x] for idx, x in enumerate(km.labels_) if x == c],2) ))\n",
    "\n",
    "    cohesion.append( np.mean( clust_coh) )\n",
    "    \n",
    "    clust_sep = []\n",
    "    for i in range(km.n_clusters):\n",
    "        for j in range(i+1,km.n_clusters):\n",
    "            clust_sep.append(np.power(distance.euclidean(km.cluster_centers_[i],km.cluster_centers_[j]),2))\n",
    "    separation.append( np.mean(clust_sep))\n",
    "\n",
    "    \n",
    "\n",
    "n_k_range = range(1,20)\n",
    "plt.figure(figsize=(10,10))\n",
    "\n",
    "plt.subplot(2,2,1)\n",
    "plt.plot(n_k_range,inertia)\n",
    "plt.title(\"Total Inertia\")\n",
    "\n",
    "plt.subplot(2,2,2)\n",
    "plt.plot(n_k_range,avgDist)\n",
    "plt.title(\"Average dist To Cluster\")\n",
    "\n",
    "plt.subplot(2,2,3)\n",
    "plt.plot(n_k_range,cohesion)\n",
    "plt.title(\"Average Cluster Cohesion\")\n",
    "\n",
    "plt.subplot(2,2,4)\n",
    "plt.plot(n_k_range,separation)\n",
    "plt.title(\"Average Cluster Separation\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
